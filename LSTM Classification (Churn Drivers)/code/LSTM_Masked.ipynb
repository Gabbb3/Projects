{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers import Bidirectional\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadr\n",
    "\n",
    "result = pyreadr.read_r('masked.rds') \n",
    "df = result[None] # extract the pandas data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning steps specific to data-set received\n",
    "# This portion has been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using just the first 100,000 rows first for initial run first, to save on computational load\n",
    "# raw_df = df.head(100000)\n",
    "raw_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank refers to the last few rides before churning (In the range of 1-10, 10 is the latest ride)\n",
    "raw_df = raw_df.sort_values(\n",
    "  by=['person','rank'], \n",
    "  ascending=[True,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latest_status refers to the whether the person has churned away from using the service or not\n",
    "raw_df[\"latest_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing other \"latest_status\" values to make it a simplier binary classification model first.\n",
    "raw_df = raw_df[raw_df.latest_status != \"Risk\"]\n",
    "raw_df = raw_df[raw_df.latest_status != \"Casual\"]\n",
    "raw_df = raw_df[raw_df.latest_status != \"Re-Activated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churned    55803\n",
       "Engaged    37832\n",
       "Name: latest_status, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simplified into a Churned vs. Engaged binary LSTM classification problem\n",
    "raw_df[\"latest_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutate and left_join back (sequential padding) to get 3D matrix for LSTM training\n",
    "from itertools import product\n",
    "\n",
    "def expand_grid(dictionary):\n",
    "   return pd.DataFrame([row for row in product(*dictionary.values())], \n",
    "                       columns=dictionary.keys())\n",
    "\n",
    "dictionary = {'dax': raw_df[\"person\"].unique(), \n",
    "              'rank': raw_df[\"rank\"].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp = expand_grid(dictionary)\n",
    "df_exp2 = pd.merge(df_exp, raw_df.drop([\"latest_status\"], axis=1), how=\"left\", on=[\"person\", \"rank\"])\n",
    "df_exp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling of input values\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaled_df_train = scaler.fit_transform(df_exp2) # Should fit_transform on train set and transform on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 1.        , ..., 0.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.        , 0.        , 1.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.82608696, 0.        , 1.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.95652174, 0.        , 1.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.26086957, 0.        , 1.        , ..., 0.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.26086957, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaled_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 1.        , ..., 0.        ,\n",
       "         1.        , 1.        ],\n",
       "        [0.        , 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.82608696, 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 1.        ],\n",
       "        [0.95652174, 0.        , 1.        , ..., 0.        ,\n",
       "         1.        , 1.        ]],\n",
       "\n",
       "       [[0.91304348, 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.43478261, 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.47826087, 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.86956522, 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.91304348, 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.91304348, 0.        , 1.        , ..., 0.        ,\n",
       "         1.        , 1.        ]],\n",
       "\n",
       "       [[0.34782609, 0.        , 1.        , ..., 0.        ,\n",
       "         1.        , 1.        ],\n",
       "        [0.39130435, 0.        , 1.        , ..., 0.        ,\n",
       "         1.        , 1.        ],\n",
       "        [0.39130435, 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.47826087, 0.        , 1.        , ..., 0.        ,\n",
       "         1.        , 1.        ],\n",
       "        [0.47826087, 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.47826087, 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.91304348, 0.        , 1.        , ..., 0.        ,\n",
       "         1.        , 1.        ],\n",
       "        [0.91304348, 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.26086957, 0.        , 1.        , ..., 0.        ,\n",
       "         1.        , 1.        ],\n",
       "        ...,\n",
       "        [0.43478261, 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.60869565, 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.69565217, 0.        , 1.        , ..., 0.        ,\n",
       "         1.        , 1.        ]],\n",
       "\n",
       "       [[0.91304348, 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.91304348, 0.        , 1.        , ..., 0.        ,\n",
       "         1.        , 1.        ],\n",
       "        [0.95652174, 0.        , 1.        , ..., 0.        ,\n",
       "         1.        , 1.        ],\n",
       "        ...,\n",
       "        [0.56521739, 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 1.        ],\n",
       "        [0.56521739, 0.        , 1.        , ..., 0.        ,\n",
       "         1.        , 1.        ],\n",
       "        [0.69565217, 0.        , 1.        , ..., 0.        ,\n",
       "         1.        , 1.        ]],\n",
       "\n",
       "       [[0.91304348, 0.        , 1.        , ..., 0.        ,\n",
       "         1.        , 0.        ],\n",
       "        [0.91304348, 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 1.        ],\n",
       "        [0.95652174, 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.95652174, 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.26086957, 0.        , 1.        , ..., 0.        ,\n",
       "         1.        , 1.        ],\n",
       "        [0.26086957, 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape into 3D array (sample, timesteps, n_features)\n",
    "X = array(rescaled_df_train).reshape(len(df_exp2[\"person\"].unique()), 10, len(df_exp2.columns)-10)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churned    8238\n",
       "Engaged    3787\n",
       "Name: latest_status, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = raw_df[[\"person\", \"latest_status\"]].drop_duplicates()\n",
    "Y[\"latest_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {\"Churned\": 0, \"Engaged\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.replace({\"latest_status\": dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y[\"latest_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y2 = array(Y).reshape(12025, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12025, 1)\n"
     ]
    }
   ],
   "source": [
    "print(Y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12025,)\n",
      "(12025, 10, 14)\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split (80/20)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y2, shuffle=True, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9620, 10, 14)\n",
      "(9620, 1)\n",
      "(2405, 10, 14)\n",
      "(2405, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9620 samples, validate on 2405 samples\n",
      "Epoch 1/30\n",
      "9620/9620 [==============================] - 3s 285us/step - loss: 0.6941 - accuracy: 0.3677 - val_loss: 0.6944 - val_accuracy: 0.3405\n",
      "Epoch 2/30\n",
      "9620/9620 [==============================] - 2s 221us/step - loss: 0.6937 - accuracy: 0.3981 - val_loss: 0.6940 - val_accuracy: 0.3825\n",
      "Epoch 3/30\n",
      "9620/9620 [==============================] - 2s 213us/step - loss: 0.6933 - accuracy: 0.4541 - val_loss: 0.6937 - val_accuracy: 0.4694\n",
      "Epoch 4/30\n",
      "9620/9620 [==============================] - 2s 220us/step - loss: 0.6930 - accuracy: 0.5280 - val_loss: 0.6933 - val_accuracy: 0.5360\n",
      "Epoch 5/30\n",
      "9620/9620 [==============================] - 2s 243us/step - loss: 0.6926 - accuracy: 0.5728 - val_loss: 0.6930 - val_accuracy: 0.5717\n",
      "Epoch 6/30\n",
      "9620/9620 [==============================] - 2s 237us/step - loss: 0.6922 - accuracy: 0.6101 - val_loss: 0.6926 - val_accuracy: 0.6054\n",
      "Epoch 7/30\n",
      "9620/9620 [==============================] - 2s 238us/step - loss: 0.6919 - accuracy: 0.6346 - val_loss: 0.6922 - val_accuracy: 0.6337\n",
      "Epoch 8/30\n",
      "9620/9620 [==============================] - 2s 238us/step - loss: 0.6915 - accuracy: 0.6558 - val_loss: 0.6919 - val_accuracy: 0.6570\n",
      "Epoch 9/30\n",
      "9620/9620 [==============================] - 2s 245us/step - loss: 0.6912 - accuracy: 0.6698 - val_loss: 0.6915 - val_accuracy: 0.6678\n",
      "Epoch 10/30\n",
      "9620/9620 [==============================] - 2s 243us/step - loss: 0.6908 - accuracy: 0.6757 - val_loss: 0.6912 - val_accuracy: 0.6711\n",
      "Epoch 11/30\n",
      "9620/9620 [==============================] - 2s 240us/step - loss: 0.6904 - accuracy: 0.6798 - val_loss: 0.6908 - val_accuracy: 0.6807\n",
      "Epoch 12/30\n",
      "9620/9620 [==============================] - 2s 255us/step - loss: 0.6901 - accuracy: 0.6839 - val_loss: 0.6905 - val_accuracy: 0.6844\n",
      "Epoch 13/30\n",
      "9620/9620 [==============================] - 3s 268us/step - loss: 0.6897 - accuracy: 0.6854 - val_loss: 0.6901 - val_accuracy: 0.6881\n",
      "Epoch 14/30\n",
      "9620/9620 [==============================] - 3s 270us/step - loss: 0.6894 - accuracy: 0.6858 - val_loss: 0.6898 - val_accuracy: 0.6881\n",
      "Epoch 15/30\n",
      "9620/9620 [==============================] - 3s 286us/step - loss: 0.6890 - accuracy: 0.6862 - val_loss: 0.6894 - val_accuracy: 0.6877\n",
      "Epoch 16/30\n",
      "9620/9620 [==============================] - 4s 411us/step - loss: 0.6887 - accuracy: 0.6852 - val_loss: 0.6891 - val_accuracy: 0.6881\n",
      "Epoch 17/30\n",
      "9620/9620 [==============================] - 4s 369us/step - loss: 0.6883 - accuracy: 0.6849 - val_loss: 0.6887 - val_accuracy: 0.6881\n",
      "Epoch 18/30\n",
      "9620/9620 [==============================] - 3s 318us/step - loss: 0.6879 - accuracy: 0.6849 - val_loss: 0.6884 - val_accuracy: 0.6877\n",
      "Epoch 19/30\n",
      "9620/9620 [==============================] - 3s 341us/step - loss: 0.6876 - accuracy: 0.6847 - val_loss: 0.6881 - val_accuracy: 0.6877\n",
      "Epoch 20/30\n",
      "9620/9620 [==============================] - 3s 330us/step - loss: 0.6872 - accuracy: 0.6843 - val_loss: 0.6877 - val_accuracy: 0.6873\n",
      "Epoch 21/30\n",
      "9620/9620 [==============================] - 3s 322us/step - loss: 0.6869 - accuracy: 0.6845 - val_loss: 0.6874 - val_accuracy: 0.6873\n",
      "Epoch 22/30\n",
      "9620/9620 [==============================] - 3s 300us/step - loss: 0.6865 - accuracy: 0.6845 - val_loss: 0.6870 - val_accuracy: 0.6873\n",
      "Epoch 23/30\n",
      "9620/9620 [==============================] - 3s 351us/step - loss: 0.6862 - accuracy: 0.6845 - val_loss: 0.6867 - val_accuracy: 0.6873\n",
      "Epoch 24/30\n",
      "9620/9620 [==============================] - 3s 343us/step - loss: 0.6858 - accuracy: 0.6845 - val_loss: 0.6864 - val_accuracy: 0.6873\n",
      "Epoch 25/30\n",
      "9620/9620 [==============================] - 4s 364us/step - loss: 0.6855 - accuracy: 0.6845 - val_loss: 0.6860 - val_accuracy: 0.6873\n",
      "Epoch 26/30\n",
      "9620/9620 [==============================] - 3s 318us/step - loss: 0.6852 - accuracy: 0.6845 - val_loss: 0.6857 - val_accuracy: 0.6873\n",
      "Epoch 27/30\n",
      "9620/9620 [==============================] - 3s 283us/step - loss: 0.6848 - accuracy: 0.6845 - val_loss: 0.6854 - val_accuracy: 0.6873\n",
      "Epoch 28/30\n",
      "9620/9620 [==============================] - 3s 261us/step - loss: 0.6845 - accuracy: 0.6845 - val_loss: 0.6851 - val_accuracy: 0.6873\n",
      "Epoch 29/30\n",
      "9620/9620 [==============================] - 2s 254us/step - loss: 0.6842 - accuracy: 0.6845 - val_loss: 0.6848 - val_accuracy: 0.6873\n",
      "Epoch 30/30\n",
      "9620/9620 [==============================] - 2s 255us/step - loss: 0.6838 - accuracy: 0.6845 - val_loss: 0.6844 - val_accuracy: 0.6873\n"
     ]
    }
   ],
   "source": [
    "# Simple LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(150, activation='relu', return_sequences=True, input_shape=(10, 14)))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-6), metrics=['accuracy'])\n",
    "#history = model.fit(X_train, Y_train, epochs=100, validation_split=0.2, verbose=1, shuffle=False, batch_size=200)\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=30, verbose=1, shuffle=False, batch_size=200, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_12 (LSTM)               (None, 10, 150)           99000     \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 50)                40200     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 139,251\n",
      "Trainable params: 139,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
